{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d871bc50-bdfd-4db7-871d-0d41056a49b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# <h1 align=\"center\"><font color=\"gree\">Projeto: Regress√£o Linear M√∫ltipla</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29aee9c6-a7d2-4292-bf2c-0a28a90c98f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<font color=\"pink\">Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c4331dc-9c6d-477e-946b-ae221b931a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Este notebook mostrar√° como criar e consultar uma ``tabela`` ou ``DataFrame`` que voc√™ enviou para o ``DBFS``. O [DBFS](https://docs.databricks.com/aws/pt/dbfs) √© o ``Sistema de Arquivos do Databricks`` que permite armazenar dados para consulta dentro do Databricks. Este notebook assume que voc√™ j√° possui um arquivo dentro do DBFS que deseja ler.\n",
    "\n",
    "Este notebook est√° escrito em ``Python``, ent√£o o tipo de c√©lula padr√£o √© Python. No entanto, voc√™ pode usar diferentes linguagens utilizando a sintaxe %LANGUAGE. ``Python``, ``Scala``, ``SQL`` e ``R`` s√£o todos suportados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">‚öôÔ∏è Configura√ß√µes para o Databricks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Carregado minhas credenciais do Databricks, com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# S√≥ executar quando estiver trabalhando localmente:\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "databricks_host = os.environ['DATABRICKS_HOST']\n",
    "databricks_token = os.environ['DATABRICKS_TOKEN']\n",
    "databricks_cluster_id = os.environ['DATABRICKS_CLUSTER_ID']\n",
    "\n",
    "print(\"üîó Carregado minhas credenciais do Databricks, com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir vamos usar `Databricks Connect` para conectar ao Databricks e executar c√≥digo `Spark` localmente, mas processando os dados remotamente no cluster Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conectado ao Databricks com sucesso!\n",
      "üîß Vers√£o Spark: 4.0.0\n",
      "üì¶ DBUtils configurado e pronto para uso!\n"
     ]
    }
   ],
   "source": [
    "from databricks.connect import DatabricksSession # Esta classe √© usada para conectar ao Databricks remotamente\n",
    "from pyspark.dbutils import DBUtils # Para usar dbutils localmente\n",
    "\n",
    "spark = DatabricksSession.builder.remote(host=databricks_host, token=databricks_token, cluster_id=databricks_cluster_id).getOrCreate()\n",
    "\n",
    "# Criar inst√¢ncia do DBUtils para usar dbutils localmente:\n",
    "dbutils = DBUtils(spark)\n",
    "\n",
    "print(\"‚úÖ Conectado ao Databricks com sucesso!\")\n",
    "print(f\"üîß Vers√£o Spark: {spark.version}\")\n",
    "print(f\"üì¶ DBUtils configurado e pronto para uso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar, s√≥ l√°, no Databricks para conhecer o ID do Cluster:\n",
    "\n",
    "#databricks_cluster_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")\n",
    "\n",
    "#print(f\"Databricks Cluster ID: {databricks_cluster_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">üìù Resumo de nosso Dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso Dataset cont√©m informa√ß√µes sobre **gorjetas de um restaurante**, com as seguintes caracter√≠sticas:\n",
    "\n",
    "**Vari√°veis:**\n",
    "- **`total_bill`** (num√©rica): Valor total da conta em d√≥lares\n",
    "- **`tip`** (num√©rica): Valor da gorjeta em d√≥lares\n",
    "- **`sex`** (categ√≥rica): Sexo do cliente (Male/Female)\n",
    "- **`smoker`** (categ√≥rica): Se o cliente √© fumante (Yes/No)\n",
    "- **`day`** (categ√≥rica): Dia da semana (Sun, Sat, Thur, Fri)\n",
    "- **`time`** (categ√≥rica): Per√≠odo da refei√ß√£o (Lunch/Dinner)\n",
    "- **`size`** (num√©rica/ordinal): Tamanho do grupo (n√∫mero de pessoas)\n",
    "\n",
    "**Objetivo do Modelo:**\n",
    "Prever o valor da **conta total** (`total_bill`) com base nas outras vari√°veis, usando **Regress√£o Linear M√∫ltipla**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81f0e3fd-e3af-4ce2-b12f-7c4c122906be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "|     23.68|3.31|  Male|    No|Sun|Dinner|   2|\n",
      "|     24.59|3.61|Female|    No|Sun|Dinner|   4|\n",
      "|     25.29|4.71|  Male|    No|Sun|Dinner|   4|\n",
      "|      8.77| 2.0|  Male|    No|Sun|Dinner|   2|\n",
      "|     26.88|3.12|  Male|    No|Sun|Dinner|   4|\n",
      "|     15.04|1.96|  Male|    No|Sun|Dinner|   2|\n",
      "|     14.78|3.23|  Male|    No|Sun|Dinner|   2|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "file_location = \"/Volumes/cat_multiple_linear_regression/schema_ml_mult_regression/vol_ml_regression_csv\"\n",
    "\n",
    "# As op√ß√µes aplicadas s√£o para arquivos CSV. Para outros tipos de arquivos, elas ser√£o ignoradas:\n",
    "df =spark.read.csv(file_location, header=True, inferSchema=True)\n",
    "\n",
    "df.show(10)\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ac3300e-e561-4099-a885-2a5dfc3b9827",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total_bill: double (nullable = true)\n",
      " |-- tip: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- smoker: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">üìä EDA (Exploratory Data Analysis)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir vou mostrar um resumo estat√≠stico do Dataset de gorjetas (``tips``) de um restaurante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìå DIMENS√ïES DO DATASET\n",
      "============================================================\n",
      "N√∫mero de registros: 244\n",
      "N√∫mero de colunas: 7\n",
      "Colunas: ['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']\n"
     ]
    }
   ],
   "source": [
    "# 1. Dimens√µes do Dataset:\n",
    "print(f\"N√∫mero de registros: {df.count()}\")\n",
    "print(f\"N√∫mero de colunas: {len(df.columns)}\")\n",
    "print(f\"Colunas: {df.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Estat√≠sticas Descritivas das Vari√°veis Num√©ricas\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä ESTAT√çSTICAS DESCRITIVAS\")\n",
    "print(\"=\" * 60)\n",
    "df.describe().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. An√°lise das Vari√°veis Categ√≥ricas\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üè∑Ô∏è  VARI√ÅVEIS CATEG√ìRICAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sexo\n",
    "print(\"\\nüìç Distribui√ß√£o por SEXO:\")\n",
    "df.groupBy(\"sex\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Fumante\n",
    "print(\"üìç Distribui√ß√£o por FUMANTE:\")\n",
    "df.groupBy(\"smoker\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Dia da semana\n",
    "print(\"üìç Distribui√ß√£o por DIA DA SEMANA:\")\n",
    "df.groupBy(\"day\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Per√≠odo (Lunch/Dinner)\n",
    "print(\"üìç Distribui√ß√£o por PER√çODO:\")\n",
    "df.groupBy(\"time\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Tamanho do grupo\n",
    "print(\"üìç Distribui√ß√£o por TAMANHO DO GRUPO:\")\n",
    "df.groupBy(\"size\").count().orderBy(\"size\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Verifica√ß√£o de Valores Nulos\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç VERIFICA√á√ÉO DE VALORES NULOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df.select([spark_sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. An√°lise de Correla√ß√£o entre Gorjeta e Conta Total\n",
    "from pyspark.sql.functions import corr\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìà CORRELA√á√ÉO ENTRE VARI√ÅVEIS NUM√âRICAS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correlation = df.stat.corr(\"total_bill\", \"tip\")\n",
    "print(f\"\\nCorrela√ß√£o entre Total da Conta e Gorjeta: {correlation:.4f}\")\n",
    "print(\"\\nüí° Interpreta√ß√£o:\")\n",
    "if correlation > 0.7:\n",
    "    print(\"   ‚úì Correla√ß√£o FORTE e positiva - quanto maior a conta, maior a gorjeta\")\n",
    "elif correlation > 0.4:\n",
    "    print(\"   ‚úì Correla√ß√£o MODERADA e positiva - existe rela√ß√£o entre conta e gorjeta\")\n",
    "else:\n",
    "    print(\"   ‚úì Correla√ß√£o FRACA - pouca rela√ß√£o linear entre as vari√°veis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10e878e4-9e51-4f4e-88fe-36d158ca1b33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "210f80b0-cf11-4901-9191-6adc0ab3c7ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Handling Categorical Features\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "524be649-e0eb-4e1c-a041-17abe2e70c5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3ad636b-e255-499f-bd47-e77eb38bfeec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "indexer=StringIndexer(inputCol=\"sex\",outputCol=\"sex_indexed\")\n",
    "df_r=indexer.fit(df).transform(df)\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e364eacf-f46a-4d26-812f-76efec56b141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "indexer=StringIndexer(inputCols=[\"smoker\",\"day\",\"time\"],outputCols=[\"smoker_indexed\",\"day_indexed\",\n",
    "                                                                  \"time_index\"])\n",
    "df_r=indexer.fit(df_r).transform(df_r)\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69fd015a-fba7-4ef4-9c37-31bc313c44cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_r.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db10023e-4cd1-418e-8025-b7da0bd89f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "featureassembler=VectorAssembler(inputCols=['tip','size','sex_indexed','smoker_indexed','day_indexed',\n",
    "                          'time_index'],outputCol=\"Independent Features\")\n",
    "output=featureassembler.transform(df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63ccd781-4562-4f15-8310-f9656f643d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output.select('Independent Features').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2262e74-0c6c-4ed8-b70c-0fb1bc50d1c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34b0087b-ed31-4232-a971-dfc702d8f796",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "finalized_data=output.select(\"Independent Features\",\"total_bill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b008089-dc86-45fd-befd-289d986421f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "finalized_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebcd1ced-d937-4531-af4d-cfea297cedb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "##train test split\n",
    "train_data,test_data=finalized_data.randomSplit([0.75,0.25])\n",
    "regressor=LinearRegression(featuresCol='Independent Features', labelCol='total_bill')\n",
    "regressor=regressor.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c492006-2d10-4516-a6d1-61bf4d04369a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07056e65-7793-405b-802b-df93cf5392fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "regressor.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4570b2dc-21f9-410c-b85c-0ce84df0d6d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Predictions\n",
    "pred_results=regressor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1ca9002-feca-4662-88dd-99347ef64033",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Final comparison\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dca9bfc-c887-449c-9c8f-cceb59413566",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### PErformance Metrics\n",
    "pred_results.r2,pred_results.meanAbsoluteError,pred_results.meanSquaredError"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "multiple_linear_regression",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
